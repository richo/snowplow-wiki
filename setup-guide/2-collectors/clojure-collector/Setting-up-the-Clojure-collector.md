[**HOME**](Home) > [**SNOWPLOW SETUP GUIDE**](SnowPlow setup guide) > [**Collectors**](choosing-a-collector) > [**Clojure collector setup**](setting-up-the-clojure-collector)

## Overview of the Clojure Collector

The Clojure collector has been designed to enable cross-domain SnowPlow deployments. As such, the Clojure collector performs one key function not performed by the [Cloudfront collector](setting up the cloudfront collector): it sets the user ID (used to identify unique visitors) server side, so that it is possible to reliably identify the same user across domains. This differs from the [Cloudfront collector](setting up the cloudfront collector), where user IDs are set on the client side.

The Clojure collector has been designed to run on [Amazon's Elastic Beanstalk][eb]. This provides two key advantages:

1. It makes it easy to deploy the Clojure collector in a scalable way
2. It makes use of Elastic Beanstalk's built in support for saving Tomcat logs into S3. These are the logs that are processed by the at the [ETL](choosing an etl module) stage to generate SnowPlow event data.

## Contents

Setting up the Clojure collector is a 6 step process:

1. [Download the Clojoure collector WAR file, or compile it from source](#war-file). (Required)
2. [Create a new application in Elastic Beanstalk, and upload the WAR file into it] (#create-eb-app). (Required)
3. [Enable logging to S3] (#enable-logging). (Required)
4. [Enable support for HTTPS](#https). (Optional, but recommended.)
5. [Set your tracker to point at the Clojure collector end point](#endpoint). (Required)
6. [Update the EmrEtlRunner configuration YAML file](#emr-etl-runner-config). (Required)

In addition, we document [additional configuration options](#configuring-the-collector) at the end of this guide.

<a name="war-file"></a>

## 1. Download the Clojoure collector `WAR` file, or compile it from source

You can download the WAR file directly from Github [here][github-download] or from S3 [here][s3-download].

Alternatively, you can build it from the source files. To do so, you will need [Leiningen][leiningen] installed. 

To do so, download the SnowPlow repo:

	$ git clone https://github.com/snowplow/snowplow.git

Navigate into the clojure collector folder:

	$ cd 2-collectors/clojure-collector

Download the required dependencies:

	$ lein deps

And then build the `war` file:

	$ lein ring uberwar

The `war` file will be saved in the `target` subdirectory.

We now need to add a couple of files to the `war`, that were not included as part of the `lein ring uberwar` command above. These files customize the format of the log files generated so that they include all the relevant data points (in particular, the `user_id`), and ensure that the log files have the same format as those generated by the [Cloudfront collector](setting up the cloudfront collector). To add both files, first navigate into the `war-resources` directory:

	$ cd war-resources

Then execute the following two commands:

	$ jar uf ../target/clojure-collector-0.1.0-standalone.war .ebextensions/server.xml 
	$ jar uf ../target/clojure-collector-0.1.0-standalone.war .ebextensions/server-update.config
	$ jar uf ../target/clojure-collector-0.1.0-standalone.war .ebextensions/cf-access-log-valve-0.0.1.jar

The `war` file is now ready to be deployed to Amazon Elastic Beanstalk.

<a name="create-eb-app"></a>

## 2. Create a new application in Elastic Beanstalk, and upload the WAR file to it

Amazon makes it easy to create a new application in Elastic Beanstalk and upload your `war` file into it. All of this is possible via the web UI.

On your web browser, log into the [AWS control panel][aws]. From the **Services** dropdown menu select **Elastic Beanstalk**. 

Before you create your application, you need to switch to the region you want your web server located. Select your region from the dropdown on the top right of the screen:

[[/setup-guide/images/clojure-collector-setup-guide/0.png]]

Once you've selected your region, you're ready to create your application. Click on the **Create application** button (located on the top right of the screen, below the top menu bar with the region selection):

[[/setup-guide/images/clojure-collector-setup-guide/1.png]]

Give your application a suitable name and description. Select **32bit Amazon Linux running Tomcat 7** for the container type. For the **Application Source**, select **Upload your Existing Application**. Use the **Choose File** button to point Elastic Beanstalk at the `war` file from [part 1](#war-file).

[[/setup-guide/images/clojure-collector-setup-guide/2.png]]

Next you need to configure the environment details. You can setup multiple environments for each application, but for our purposes one is enough.

Keep the **Launch a new environment running this application** checkbox checked (i.e. selected), but **deselect** the 2nd option: **Create an RDS DB Instance with this environment**. We do **not** need a database to run the collector.

Give your environment a suitable name, URL and description:

[[/setup-guide/images/clojure-collector-setup-guide/3.png]]

Next we need to specify another set of configuration details. Set a suitable instance type (we recommend at least `m1.small`). If you have an EC2 key pair configured, you can enter the key pair name at this stage: this will enable you to use the key pair to SSH in should you wish. (This is not required, and can be added later without any difficulty.)

For the **Application Health Check URL** enter a single slash i.e. `/`:

[[/setup-guide/images/clojure-collector-setup-guide/4.png]]

Click **Continue**. Amazon gives you the chance to review your inputs. When you've checked them click **Finish**. 

Amazon then sets up your the application and environment. When this is complete, you should see a screen like the one below. Note the green box, and the **Successflly running version First Release** notice.

[[/setup-guide/images/clojure-collector-setup-guide/5.png]]

To test that all is working as expected, select the **Environment Details** dropdown:

[[/setup-guide/images/clojure-collector-setup-guide/7.png]]

Click on the **URL** link. (This is [[http://cc-endpoint.elasticbeanstalk.com]] in the example above.) This should return a 404. If you add `/i' to the path (e.g. `http://cc-endpoint.elasticbeanstalk.com/i`), right click on the window and select **Inspect Element** in Chrome or **Inspect with Firebug** in Firefox, you should be able to see if the cookie has been set:

[[/setup-guide/images/clojure-collector-setup-guide/8.png]]

<a name="enable-logging"></a>

## 3. Enable logging to S3

Now that your application is up and running, you need to update the configuration so that the Tomcat logs are pushed to S3. (These will be processed by the [etl][etl] step to generate your SnowPlow data.) Click on the **Actions** dropdown and select **Edit/Load configuration**.

[[/setup-guide/images/clojure-collector-setup-guide/6.png]]

Select the **Container** tab in the dialogue box, and then check the box marked **Enable log file rotation to Amazon S3**:

[[/setup-guide/images/clojure-collector-setup-guide/9.png]]

Click the **Apply changes** button. The environment update will be processed, and the collector app should be live again after a few minutes.

### Checking that your logs are being pushed to S3

Amazon pushes Tomcat access logs to S3 hourly. (In our experience, they generally appear 10 minutes passed each hour.) Finding your logs in S3, however, is not entirely trivial...

On the Amazon Web Services console, navigate to the EC2 section of the site, and click on the **Instances** item in the Navigation menu on the left hand side. A list of all the EC2 instances you are running should show as below:

[[/setup-guide/images/clojure-collector-setup-guide/12.png]]

You should see at least one instance with the name given to the environment you created above. (In our case, 'cc-endpoint'.) Select it:

[[/setup-guide/images/clojure-collector-setup-guide/13.png]]

There are two identifiers we need to take note of. The first is the **security group** (highlighted in the screenshot above). Here we are interested in the characters between `awseb-` and `-stack-AWSEBSecurityGroup` i.e. in our case, `e-bgp9nsynv7`. The other identifier we need to note is the Instance identifier listed both in the summary menu (under **My Instances**) and in the more detailed pane. In our case, this is `i-ff035fb4`.

Now that we have those two identifiers, we can locate the logs in S3. In the web console, navigate to the S3 section. On the left hand side, you should see at least one bucket with a name that begins `elasticbeanstalk` and then follows with the region you setup Elastic Beanstalk in:

[[/setup-guide/images/clojure-collector-setup-guide/14.png]]

Select that bucket - you should find a folder within it called resources. Within that folder you should find another called `environments`. Within that folder you should find a logs folder, within that a publish folder and within that a folder with the security group identifier you noted above. (In our case `e-bgp9nsynv7`.) Within that folder you should find another with your instance identifier, also noted above. (In our case, `i-ff035fb4`.) The path to your logs is therefore:

	s3://elasticbeanstalk-{{REGION NAME}}-{{UUID}}/resources/environments/logs/{{SECURITY GROUP IDENTIFIER}}/{{INSTANCE IDENTIFIER}}

These logs will be processed by the [EmrEtlRunner](#emr-etl-runner).

Note - if you cannot find the logs as described above, it may be because Amazon has not written any yet. You may need to wait an hour for the logs to appear.




<a name="https"></a>

## 4. Enable support for HTTPS (optional but highly recommended)

In order to track user behaviour on HTTPS web pages (e.g. shop checkouts), it is necessary to configure HTTPS for your AWS Elastic Beanstalk Environment. This requires that you use a custom domain as your endpoint (rather than the `{{ENVIRONMENT-NAME}}.elasticbeanstalk.com`) and have purchased an SSL certificate for that custom domain.

### 4.1 Using custom domains

Using a custom domain is straightforward. In this tutorial, we will use the custom domain `collector.snplow.com`. We own the domain `snplow.com` and have it managed through [Linode][linode]. If you host a domain name with a different 3rd party to Linode, the steps will be broadly the same, although the UI will likely be different. If you use Amazon Route 53 to host your domains, instructions on using these with Elastic Beanstalk can be found [here][route-53]. 

To use a custom domain, all we have to do is create a CNAME with our DNS provider, and map that CNAME to our Elastic Beanstalk environment URL. (In our case, `cc-endpoint.elasticbeanstalk.com`.) In Linode, we login and naviage to the **DNS Manager**, where we select the custom domain we want to use i.e. `snplow.com` and scroll down to the **CNAME Records**:

[[/setup-guide/images/clojure-collector-setup-guide/15.png]]

We enter the host name we want to use for our collector (we'll use `collector.snplow.com`), alias it to our Elastic Beanstalk environment URL (`cc-endpoint.elasticbeanstalk.com`) and set the TTL to the shortest time that our provider offers:

[[/setup-guide/images/clojure-collector-setup-guide/16.png]]

In due course, we should be able to enter our custom domain with a `/i` in a browser URL window (in our case `collector.snplow.com`). Inspecting the page with developer tools, we should be able to see that a cookie has been set i.e. the domain is correcting aliasing our collector on Elastic Beanstalk:

[[/setup-guide/images/clojure-collector-setup-guide/18.png]]

### 4.2 Configuring HTTPS for Elastic Beanstalk

Now that we are running our collector on our own domain, we can serve it via HTTPS. 

#### 4.2.1 Pre-requisites

1. An SSL certificate for your custom domain
2. [OpenSSL][open-ssl]
3. [Java][java]. This is required by the Amazon command line tools which are used to upload your security certificate to Amazon.

#### 4.2.2 Steps required

The following will walk you through the process of enabling HTTPS using a wildcard SSL certificate purchased from [Comodo][comodo] and setup using Linux / Ubuntu. For instructions on performing the setup on a Windows machine consult the [Amazon guide][amazon-https-eb-setup].

The following steps are required to setup SSL:

1. [Download and install the AWS Identity and Access Management (IAM) command line tools](#download-and-install-cli)  
2. [Use OpenSSL to convert the signed certificates received from your SSL provider (in our case, Comodo) into a format suitable for Amazon](#openssl-prep-keys)  
3. [Use the command line tools to upload the certificates to Amazon](#upload-cert-to-amazon)  
4. [Update your Elastic Beanstalk environment to use HTTPS](#use-https)  

<a name="download-and-install-cli"></a>

#### 4.2.1 Download and install AWS Identity and Access Management command line tools

Navigate [here](http://aws.amazon.com/developertools/AWS-Identity-and-Access-Management/4143) and click the download button.

Extract the contents of the zip file to a suitable location on your hard drive.

Now we need to set a variable `JAVA_HOME` and point it at our JAVA installation. At the command prompt:

	$ export JAVA_HOME=/usr/lib/jvm/java-6-sun

(You may need to alter the location of `JAVA_HOME` depending on where yours lives.)

Now set the variable `AWS-IAM_HOME` to the location where you saved the command line tools:

	$ export AWS_IAM_HOME=~/Apps/IAMCli-1.5.0

(Again - update the path to reflect the location you extracted the tools to.) For simplicity, add the tools to your `PATH` directory:

	$ export PATH=$AWS_IAM_HOME/bin:$PATH

Use a text-editor to create a file in command line tools directory with your AWS Access Key and Secret Key specified e.g.:
	
	AWSAccessKeyId=AKIAIOSFODNN7EXAMPLE
	AWSSecretKey=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

You can get these details from the AWS Management Console, by clicking on your username (top right of the screen) and selecting **Security Credentials**.

[[/setup-guide/images/clojure-collector-setup-guide/17.png]]

Save the file down. (The  name doesn't matter - we called ours `account-key`.) Now set `AWS_CREDENTIAL_FILE` to the path and filename of the credential file you just created e.g.

	$ export AWS_CREDENTIAL_FILE=~/Apps/IAMCli-1.5.0/account-key

To check your installation is working, try running `iam-usercreate -h` at the command prompt. You should see:

	Creates a new user in your account. You can also optionally add the user to one or more groups, and create an access key for the user.
	iam-usercreate [options...] arguments...
	 --aws-credential-file CREDENTIALFILE  : path to the file containing your AWS cr
	                                         edentials
	 --client-config-file CLIENTCONFIGFILE : path to the file containing client conf
	                                         igurations
	 --url SERVICEENDPOINT                 : endpoint URL to be used when making the
	                                          service call
	 -d (--debug)                          : enable debug logging
	 -g GROUPS                             : add user to group(s)
	 -h                                    : print out this message
	 -k                                    : create a key for the user
	 -p PATH                               : the path of the user, defaults to /
	 -u USERNAME                           : the name of the user
	 -v VERBOSE                            : print out the newly created user's arn 
	                                         and guid

<a name="openssl-prep-keys" ></a>

#### 4.2.2 Use OpenSSL to convert the signed certificates received from your SSL provider (in our case, Comodo) into a format suitable for Amazon.

When we bought our SSL wildcard certificate for `snplow.com` domain, we received three files from Comodo:

1. `STAR_snplow_com.crt`. This is the file that is unique to our domain.
2. `AddTrustExternalCARoot.crt`. This is the root certificate for our domain.
3. `PostiveSSLCA2.crt`. This is an intermediate certificate, which is used which the root certificate (above) to form a certificate chain for our domain.

In addition, when we applied for the SSL certificate, we generated a private key file called `snplow-ssl.key`. We will need to use this again, now.

There are four things we need to upload into Amazon to enable HTTPS on our collector:

1. A `pem` encoded private key file. This will be generated from `snplow-ssl.key`.
2. The `pem` encoded public domain certficate. This will be generated from `STAR-snplow_com.crt`
3. A `pem` encoded certificate chain file. This will be generated from `AddTrustExternalCaRoot.crt` and `PositiveSSLCA2.crt`.


We use OpenSSL to create the `pem` encoded private key file. Navigate to the directory where your private key lives and execute the following command:

	openssl rsa -in snplow-ssl.key -out snplow-ssl.pem

Note: you will need to substitute the  name of your private key for our `snplow-ssl.key` and the name of the `.pem` file you create for `snplow-ssl.pem`. This will be one of the files you upload to Amazon.

We use OpenSSL to create the `pem` encoded public domain certificate, by executing the following command:

	openssl x509 -inform PEM -in STAR_snplow_com.crt -out STAR_snplow_com.pem

And again, we use OpenSSL to create the `pem` encoded certificate chain file:

	(openssl x509 -inform PEM -in PositiveSSLCA2.crt; openssl x509 -inform PEM -in AddTrustExternalCARoot.crt) > certificate-chain-file.crt

Now we're ready to upload our certificate to Amazon.

<a name="upload-cert-to-amazon" ></a>

#### 4.2.3 Upload the certificate to Amazon

Execute the following command at the command prompt to upload the certificate to Amazon:

	$ iam-servercertupload -b STAR_snplow_com.pem -c certificate-chain-file.crt -k snplow-ssl.pem -s snplow_certificate

Notes:

* Substitute in your PEM encoded certificate body file for `STAR-snplow_com.pem` i.e. the file you created from the domain specific file you received when you bought the SSL certificate
* Substitute in your PEM encoded certificate key chain file for `certificate-chain-file.crt`
* Substitute in your PEM encoded private key file for `snplow-ssl.pem`
* You can choose whatevert name you give your certificate (we've used `snplow_certificate`). Just make a note of your choice, as you'll need to reference it within Amazon.

You then need to get your SSL Certificate ID from Elastic Beanstalk, by running the following command:

	$ iam-servercertgetattributes -s snplow_certificate

Amazon will respond with something like:

	arn:aws:iam::889434468096:server-certificate/snplow_certificate
	ASCAJLVQA7JJZQYPM64FC

The first line (i.e. `arn:aws:iam::889434468096:server-certificate/snplow_certificate`) is the **Amazon Resource Number** (ARN). Take a note of yours, we will need this in the next step.

<a name="use-https"></a>

#### 4.2.4 Update your Elastic Beanstalk environment to use HTTPS

Return back to the AWS Management Console ([[console.aws.amazon.com]]). In the Elastic Beanstalk section, select your environment and choose to **Edit / load configuration** from the **Actions** dropdown. Then select **Load Balancer** from the tab:

[[/setup-guide/images/clojure-collector-setup-guide/19.png]]

Set the **HTTPS Listener Port** to on (either 443 or 8443) and add your ARN into the **SSL Certificate ID** field:

[[/setup-guide/images/clojure-collector-setup-guide/20.png]]

Click the **Apply Changes** button. The environment will update. When it has completed, you will be able to test that HTTPS access is working, by using your browser to navigate to `https://{{MY CUSTOM COLLECTOR DOMAIN}}/i` and look to see if the cookie is set via developer tools:

[[/setup-guide/images/clojure-collector-setup-guide/20.png]]

Note the padlock icon by the address bar.

<a name="endpoint" ></a>

## 5. Set your tracker to point at the Clojure collector end point

Now that you've set up your Clojure collector, you need to configure your tracker to send event data to it.

Assuming you're using the [Javascript tracker][javascript-tracker], you'll need to modify your Javascript tracking tags to set the correct end point. The standard tracking tags look as follows:

```html
<!-- SnowPlow starts plowing -->
<script type="text/javascript">
var _snaq = _snaq || [];

_snaq.push(['setCollectorCf', '{{CLOUDFRONT DOMAIN}}']);
_snaq.push(['trackPageView']);
_snaq.push(['enableLinkTracking']);

(function() {
var sp = document.createElement('script'); sp.type = 'text/javascript'; sp.async = true; sp.defer = true;
sp.src = ('https:' == document.location.protocol ? 'https' : 'http') + '://d1fc8wv8zag5ca.cloudfront.net/0.8.1/sp.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(sp, s);
})();
 </script>
<!-- SnowPlow stops plowing -->
```

The line

```javascript
_snaq.push(['setCollectorCf', '{{CLOUDFRONT DOMAIN}}']);
```

Is the one that sets the end point, and assumes that you're using the Cloudfront collector rather than the Clojure collector.

To set your Clojure collector as the end point, remove that line and replace it with:

```javascript
_snaq.push(['setCollectorUrl', '{{COLLECTOR URL}}'])
```

Note that the URL your enter must **exclude** `http` or `https`. In our case, the url would be: `collector.snplow.com`. As a result, the complete tag will look like:

```html
<!-- SnowPlow starts plowing -->
<script type="text/javascript">
var _snaq = _snaq || [];

_snaq.push(['setCollectorUrl', 'collector.snplow.com']);
_snaq.push(['trackPageView']);
_snaq.push(['enableLinkTracking']);

(function() {
var sp = document.createElement('script'); sp.type = 'text/javascript'; sp.async = true; sp.defer = true;
sp.src = ('https:' == document.location.protocol ? 'https' : 'http') + '://d1fc8wv8zag5ca.cloudfront.net/0.8.1/sp.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(sp, s);
})();
 </script>
<!-- SnowPlow stops plowing -->
```

<a name="emr-etl-runner-config" />

## 6. Update the EmrEtlRunner configuration YAML file

TO WRITE THIS SECTION

	:etl:
	  :collector_format: clj-tomcat




<a name="configuring-the-collector"></a>

## Appendix: Configuring the collector

There are a environment configuration parameters that you may want to consider tailoring to your specific needs. All of them can be accessed via the **Edit Configuration** dialogue box in the AWS Managemetn Console.

<a name="3bi" ></a>

#### 3b i. Setting the environment to develop or production

You can set an environment mode in the collector to "development" or "production". This can be set via the Elastic Beanstalk UI. Simply select **Edit configuration**, select the **Conatainer** tab and scroll down. Enter your desired environment name in **Param1** and then select **Apply Changes**:

[[/setup-guide/images/clojure-collector-setup-guide/10.png]]

Setting the environment to 'development' means you can view the status of the collector on `http://{{COLLECTOR URL}}/status`. It is set to production by default.

<a name="3bii" ></a>

#### 3b ii. Setting the P3P policy header

This can be entered directly into the same dialogue box as the environment name (see [3b i](#3bi) above), but in **Param2** rather than **Param1**.

If it is not set, the PÂ£3P policy header defaults to:

	policyref="/w3c/p3p.xml", CP="NOI DSP COR NID PSA OUR IND COM NAV STA"

<a name="3biii" ></a>

#### 3b iii. Setting the domain name

The domain name can be entered directly into the same dialogue box as the [environment name](#3bi) and [P3P policy header](#3bii) by entering it into **Param3**.

Setting the domain name can be useful if you want to make the cookie accessible to other applications on your domain. In our example above, for example, we've setup the collector on `collector.snplow.com`. If we do not set a domain name, the cookie will default to thsi domain. However, if we set it to `.snplow.com`, that cookie will be accessible to other applications running on `*.snplow.com`.

<a name="3biv" ></a>

#### 3b iv. Setting the cookie duration

This can be entered into the same dialogue box as the [environment name](#3bi), [P3P policy header](#3bii) and [domain name](#3biii), by entering the value in **Param4**. The value entered should be an integer representing cookie duration measured in days.

If no value is provided, cookies set default to expiring after one year (i.e. 365 days).

#### 3b v. Auto scaling

Elastic Beanstalk can scale up the number of webservers running the collector to handle spikes in traffic.

Basic settings (minimum and maximum numbers of servers) can be set in the configuration dialogue box, under the **Auto Scaling** tab. 

[[/setup-guide/images/clojure-collector-setup-guide/11.png]]

You can tell Amazon in what circumstances to launch new instances by setting 'triggers'. More details on tuning Elastic Beanstalk can be found [here](http://docs.amazonwebservices.com/elasticbeanstalk/latest/dg/using-features.managing.as.html).


[eb]: http://aws.amazon.com/elasticbeanstalk/
[github-download]: https://github.com/snowplow/snowplow/downloads
[s3-download]: https://github.com/snowplow/snowplow/wiki/Hosted-assets
[leiningen]: https://github.com/technomancy/leiningen
[aws]: https://console.aws.amazon.com/
[linode]: http://www.linode.com/
[route-53]: http://docs.amazonwebservices.com/elasticbeanstalk/latest/dg/customdomains.html
[open-ssl]: http://www.openssl.org/
[comodo]: http://ssl.comodo.com/index.php?ap=ComodoSSLJun12&key1sk5=3159&key1sk1=sem&gclid=CLzP7KPOhbQCFe7MtAodBAsApQ
[amazon-https-eb-setup]: http://docs.amazonwebservices.com/elasticbeanstalk/latest/dg/configuring-https.html
[java]: http://www.oracle.com/technetwork/java/javase/downloads/index.html
[javascript-tracker]: javascript-tracker-setup
